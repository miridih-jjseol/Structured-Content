{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 4008,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007487832272557095,
      "grad_norm": 0.30187815913360766,
      "learning_rate": 2.2443890274314216e-06,
      "loss": 0.6003,
      "step": 10
    },
    {
      "epoch": 0.01497566454511419,
      "grad_norm": 0.38605781322725696,
      "learning_rate": 4.738154613466334e-06,
      "loss": 0.5967,
      "step": 20
    },
    {
      "epoch": 0.022463496817671284,
      "grad_norm": 0.40133331482488727,
      "learning_rate": 7.231920199501248e-06,
      "loss": 0.5751,
      "step": 30
    },
    {
      "epoch": 0.02995132909022838,
      "grad_norm": 0.3501505842901066,
      "learning_rate": 9.72568578553616e-06,
      "loss": 0.559,
      "step": 40
    },
    {
      "epoch": 0.037439161362785474,
      "grad_norm": 0.36009028204489185,
      "learning_rate": 1.2219451371571072e-05,
      "loss": 0.5032,
      "step": 50
    },
    {
      "epoch": 0.04492699363534257,
      "grad_norm": 0.41231944032222384,
      "learning_rate": 1.4713216957605986e-05,
      "loss": 0.4131,
      "step": 60
    },
    {
      "epoch": 0.05241482590789966,
      "grad_norm": 0.38183667986642206,
      "learning_rate": 1.7206982543640898e-05,
      "loss": 0.3275,
      "step": 70
    },
    {
      "epoch": 0.05990265818045676,
      "grad_norm": 0.31415985515160727,
      "learning_rate": 1.9700748129675812e-05,
      "loss": 0.2473,
      "step": 80
    },
    {
      "epoch": 0.06739049045301385,
      "grad_norm": 0.25855488729934184,
      "learning_rate": 2.2194513715710726e-05,
      "loss": 0.2061,
      "step": 90
    },
    {
      "epoch": 0.07487832272557095,
      "grad_norm": 0.2870736440603118,
      "learning_rate": 2.4688279301745636e-05,
      "loss": 0.1857,
      "step": 100
    },
    {
      "epoch": 0.08236615499812804,
      "grad_norm": 0.33542293158135456,
      "learning_rate": 2.718204488778055e-05,
      "loss": 0.1655,
      "step": 110
    },
    {
      "epoch": 0.08985398727068514,
      "grad_norm": 0.32387175414222835,
      "learning_rate": 2.9675810473815464e-05,
      "loss": 0.1644,
      "step": 120
    },
    {
      "epoch": 0.09734181954324223,
      "grad_norm": 0.31567266696107027,
      "learning_rate": 3.216957605985038e-05,
      "loss": 0.1569,
      "step": 130
    },
    {
      "epoch": 0.10482965181579933,
      "grad_norm": 0.26083215831512463,
      "learning_rate": 3.466334164588529e-05,
      "loss": 0.1491,
      "step": 140
    },
    {
      "epoch": 0.11231748408835641,
      "grad_norm": 0.3870494694555868,
      "learning_rate": 3.71571072319202e-05,
      "loss": 0.1435,
      "step": 150
    },
    {
      "epoch": 0.11980531636091352,
      "grad_norm": 0.30130333138729654,
      "learning_rate": 3.965087281795511e-05,
      "loss": 0.1425,
      "step": 160
    },
    {
      "epoch": 0.1272931486334706,
      "grad_norm": 0.41791861880449416,
      "learning_rate": 4.214463840399003e-05,
      "loss": 0.1315,
      "step": 170
    },
    {
      "epoch": 0.1347809809060277,
      "grad_norm": 0.2827781973769702,
      "learning_rate": 4.463840399002494e-05,
      "loss": 0.1281,
      "step": 180
    },
    {
      "epoch": 0.1422688131785848,
      "grad_norm": 0.3247855637602416,
      "learning_rate": 4.7132169576059854e-05,
      "loss": 0.1214,
      "step": 190
    },
    {
      "epoch": 0.1497566454511419,
      "grad_norm": 0.294925349702893,
      "learning_rate": 4.962593516209477e-05,
      "loss": 0.1237,
      "step": 200
    },
    {
      "epoch": 0.15724447772369898,
      "grad_norm": 0.41374143996376306,
      "learning_rate": 5.2119700748129675e-05,
      "loss": 0.1162,
      "step": 210
    },
    {
      "epoch": 0.16473230999625607,
      "grad_norm": 0.31996675442767847,
      "learning_rate": 5.461346633416459e-05,
      "loss": 0.1193,
      "step": 220
    },
    {
      "epoch": 0.1722201422688132,
      "grad_norm": 0.3196931893143027,
      "learning_rate": 5.7107231920199497e-05,
      "loss": 0.1133,
      "step": 230
    },
    {
      "epoch": 0.17970797454137027,
      "grad_norm": 0.3840531675444239,
      "learning_rate": 5.960099750623441e-05,
      "loss": 0.1047,
      "step": 240
    },
    {
      "epoch": 0.18719580681392736,
      "grad_norm": 0.3917040273203432,
      "learning_rate": 6.209476309226932e-05,
      "loss": 0.1077,
      "step": 250
    },
    {
      "epoch": 0.19468363908648445,
      "grad_norm": 0.27569995915776363,
      "learning_rate": 6.458852867830424e-05,
      "loss": 0.1092,
      "step": 260
    },
    {
      "epoch": 0.20217147135904157,
      "grad_norm": 0.37668012696660436,
      "learning_rate": 6.708229426433915e-05,
      "loss": 0.1032,
      "step": 270
    },
    {
      "epoch": 0.20965930363159865,
      "grad_norm": 0.47538795764549074,
      "learning_rate": 6.957605985037406e-05,
      "loss": 0.1057,
      "step": 280
    },
    {
      "epoch": 0.21714713590415574,
      "grad_norm": 0.29018086970994433,
      "learning_rate": 7.206982543640898e-05,
      "loss": 0.1037,
      "step": 290
    },
    {
      "epoch": 0.22463496817671283,
      "grad_norm": 0.36060562296148685,
      "learning_rate": 7.456359102244389e-05,
      "loss": 0.1016,
      "step": 300
    },
    {
      "epoch": 0.23212280044926994,
      "grad_norm": 0.3209285096706107,
      "learning_rate": 7.705735660847881e-05,
      "loss": 0.099,
      "step": 310
    },
    {
      "epoch": 0.23961063272182703,
      "grad_norm": 0.2996649753284886,
      "learning_rate": 7.955112219451371e-05,
      "loss": 0.1065,
      "step": 320
    },
    {
      "epoch": 0.24709846499438412,
      "grad_norm": 0.2984815536033914,
      "learning_rate": 8.204488778054864e-05,
      "loss": 0.0945,
      "step": 330
    },
    {
      "epoch": 0.2545862972669412,
      "grad_norm": 0.30620867202387103,
      "learning_rate": 8.453865336658354e-05,
      "loss": 0.0952,
      "step": 340
    },
    {
      "epoch": 0.2620741295394983,
      "grad_norm": 0.2743270705660031,
      "learning_rate": 8.703241895261845e-05,
      "loss": 0.0945,
      "step": 350
    },
    {
      "epoch": 0.2695619618120554,
      "grad_norm": 0.22797591685017193,
      "learning_rate": 8.952618453865337e-05,
      "loss": 0.0911,
      "step": 360
    },
    {
      "epoch": 0.2770497940846125,
      "grad_norm": 0.3009922395195426,
      "learning_rate": 9.201995012468828e-05,
      "loss": 0.0917,
      "step": 370
    },
    {
      "epoch": 0.2845376263571696,
      "grad_norm": 0.30734487382191716,
      "learning_rate": 9.45137157107232e-05,
      "loss": 0.0888,
      "step": 380
    },
    {
      "epoch": 0.2920254586297267,
      "grad_norm": 0.24637499545684735,
      "learning_rate": 9.70074812967581e-05,
      "loss": 0.0912,
      "step": 390
    },
    {
      "epoch": 0.2995132909022838,
      "grad_norm": 0.28384177839407765,
      "learning_rate": 9.950124688279303e-05,
      "loss": 0.0944,
      "step": 400
    },
    {
      "epoch": 0.3070011231748409,
      "grad_norm": 0.3080159206766401,
      "learning_rate": 9.999878625993977e-05,
      "loss": 0.0909,
      "step": 410
    },
    {
      "epoch": 0.31448895544739797,
      "grad_norm": 0.22900475331240375,
      "learning_rate": 9.999385554193728e-05,
      "loss": 0.0866,
      "step": 420
    },
    {
      "epoch": 0.3219767877199551,
      "grad_norm": 0.2670491064645251,
      "learning_rate": 9.99851323609883e-05,
      "loss": 0.0942,
      "step": 430
    },
    {
      "epoch": 0.32946461999251214,
      "grad_norm": 0.2632338381797619,
      "learning_rate": 9.997261737882097e-05,
      "loss": 0.0843,
      "step": 440
    },
    {
      "epoch": 0.33695245226506926,
      "grad_norm": 0.26040073455018004,
      "learning_rate": 9.995631154480406e-05,
      "loss": 0.0832,
      "step": 450
    },
    {
      "epoch": 0.3444402845376264,
      "grad_norm": 0.25456969309953315,
      "learning_rate": 9.993621609587503e-05,
      "loss": 0.0834,
      "step": 460
    },
    {
      "epoch": 0.35192811681018343,
      "grad_norm": 0.22422343907997777,
      "learning_rate": 9.991233255644609e-05,
      "loss": 0.0856,
      "step": 470
    },
    {
      "epoch": 0.35941594908274055,
      "grad_norm": 0.26353826161700855,
      "learning_rate": 9.988466273828868e-05,
      "loss": 0.0829,
      "step": 480
    },
    {
      "epoch": 0.36690378135529766,
      "grad_norm": 0.28495839832459924,
      "learning_rate": 9.985320874039595e-05,
      "loss": 0.0836,
      "step": 490
    },
    {
      "epoch": 0.3743916136278547,
      "grad_norm": 0.2091299325536181,
      "learning_rate": 9.981797294882351e-05,
      "loss": 0.0843,
      "step": 500
    },
    {
      "epoch": 0.38187944590041184,
      "grad_norm": 0.3017538031401336,
      "learning_rate": 9.977895803650856e-05,
      "loss": 0.0774,
      "step": 510
    },
    {
      "epoch": 0.3893672781729689,
      "grad_norm": 0.2762556936280959,
      "learning_rate": 9.973616696306698e-05,
      "loss": 0.0784,
      "step": 520
    },
    {
      "epoch": 0.396855110445526,
      "grad_norm": 0.27015375654389484,
      "learning_rate": 9.968960297456886e-05,
      "loss": 0.0888,
      "step": 530
    },
    {
      "epoch": 0.40434294271808313,
      "grad_norm": 0.2499890782475504,
      "learning_rate": 9.963926960329233e-05,
      "loss": 0.0814,
      "step": 540
    },
    {
      "epoch": 0.4118307749906402,
      "grad_norm": 0.2130651767405544,
      "learning_rate": 9.958517066745551e-05,
      "loss": 0.0835,
      "step": 550
    },
    {
      "epoch": 0.4193186072631973,
      "grad_norm": 0.26672672378977486,
      "learning_rate": 9.952731027092691e-05,
      "loss": 0.0764,
      "step": 560
    },
    {
      "epoch": 0.4268064395357544,
      "grad_norm": 0.2450292626481364,
      "learning_rate": 9.946569280291411e-05,
      "loss": 0.0781,
      "step": 570
    },
    {
      "epoch": 0.4342942718083115,
      "grad_norm": 0.31497342663729655,
      "learning_rate": 9.940032293763081e-05,
      "loss": 0.0799,
      "step": 580
    },
    {
      "epoch": 0.4417821040808686,
      "grad_norm": 0.25721111017361487,
      "learning_rate": 9.933120563394222e-05,
      "loss": 0.0796,
      "step": 590
    },
    {
      "epoch": 0.44926993635342566,
      "grad_norm": 0.26456017163184864,
      "learning_rate": 9.925834613498897e-05,
      "loss": 0.0734,
      "step": 600
    },
    {
      "epoch": 0.4567577686259828,
      "grad_norm": 0.2966148633216811,
      "learning_rate": 9.918174996778924e-05,
      "loss": 0.0781,
      "step": 610
    },
    {
      "epoch": 0.4642456008985399,
      "grad_norm": 0.305087083437524,
      "learning_rate": 9.910142294281963e-05,
      "loss": 0.0779,
      "step": 620
    },
    {
      "epoch": 0.47173343317109695,
      "grad_norm": 0.19562858342955525,
      "learning_rate": 9.901737115357423e-05,
      "loss": 0.0773,
      "step": 630
    },
    {
      "epoch": 0.47922126544365407,
      "grad_norm": 0.2289072973285452,
      "learning_rate": 9.892960097610253e-05,
      "loss": 0.0746,
      "step": 640
    },
    {
      "epoch": 0.4867090977162112,
      "grad_norm": 0.25394096736010197,
      "learning_rate": 9.883811906852569e-05,
      "loss": 0.076,
      "step": 650
    },
    {
      "epoch": 0.49419692998876824,
      "grad_norm": 0.27220178138982987,
      "learning_rate": 9.874293237053136e-05,
      "loss": 0.0779,
      "step": 660
    },
    {
      "epoch": 0.5016847622613253,
      "grad_norm": 0.1868167556921312,
      "learning_rate": 9.864404810284746e-05,
      "loss": 0.0789,
      "step": 670
    },
    {
      "epoch": 0.5091725945338824,
      "grad_norm": 0.20270110786401907,
      "learning_rate": 9.854147376669419e-05,
      "loss": 0.0736,
      "step": 680
    },
    {
      "epoch": 0.5166604268064395,
      "grad_norm": 0.2526851852772454,
      "learning_rate": 9.843521714321513e-05,
      "loss": 0.0757,
      "step": 690
    },
    {
      "epoch": 0.5241482590789966,
      "grad_norm": 0.2370361159532856,
      "learning_rate": 9.832528629288703e-05,
      "loss": 0.0702,
      "step": 700
    },
    {
      "epoch": 0.5316360913515538,
      "grad_norm": 0.2576324434999543,
      "learning_rate": 9.821168955490818e-05,
      "loss": 0.0738,
      "step": 710
    },
    {
      "epoch": 0.5391239236241108,
      "grad_norm": 0.21560416818399813,
      "learning_rate": 9.809443554656595e-05,
      "loss": 0.0683,
      "step": 720
    },
    {
      "epoch": 0.5466117558966679,
      "grad_norm": 0.20106234946275742,
      "learning_rate": 9.797353316258304e-05,
      "loss": 0.0711,
      "step": 730
    },
    {
      "epoch": 0.554099588169225,
      "grad_norm": 0.2853701542468898,
      "learning_rate": 9.784899157444277e-05,
      "loss": 0.0737,
      "step": 740
    },
    {
      "epoch": 0.5615874204417821,
      "grad_norm": 0.22971461889110692,
      "learning_rate": 9.77208202296933e-05,
      "loss": 0.072,
      "step": 750
    },
    {
      "epoch": 0.5690752527143392,
      "grad_norm": 0.234856780445851,
      "learning_rate": 9.758902885123098e-05,
      "loss": 0.0707,
      "step": 760
    },
    {
      "epoch": 0.5765630849868963,
      "grad_norm": 0.2018762812506017,
      "learning_rate": 9.745362743656279e-05,
      "loss": 0.0738,
      "step": 770
    },
    {
      "epoch": 0.5840509172594534,
      "grad_norm": 0.23058986912306992,
      "learning_rate": 9.731462625704793e-05,
      "loss": 0.0741,
      "step": 780
    },
    {
      "epoch": 0.5915387495320105,
      "grad_norm": 0.2573914747812213,
      "learning_rate": 9.717203585711862e-05,
      "loss": 0.0673,
      "step": 790
    },
    {
      "epoch": 0.5990265818045676,
      "grad_norm": 0.25583679122580627,
      "learning_rate": 9.702586705348034e-05,
      "loss": 0.0738,
      "step": 800
    },
    {
      "epoch": 0.6065144140771247,
      "grad_norm": 0.24302918201547133,
      "learning_rate": 9.68761309342911e-05,
      "loss": 0.0665,
      "step": 810
    },
    {
      "epoch": 0.6140022463496818,
      "grad_norm": 0.1970177686471821,
      "learning_rate": 9.672283885832045e-05,
      "loss": 0.072,
      "step": 820
    },
    {
      "epoch": 0.6214900786222388,
      "grad_norm": 0.23189466076516624,
      "learning_rate": 9.656600245408779e-05,
      "loss": 0.069,
      "step": 830
    },
    {
      "epoch": 0.6289779108947959,
      "grad_norm": 0.21292904419841385,
      "learning_rate": 9.640563361898018e-05,
      "loss": 0.0689,
      "step": 840
    },
    {
      "epoch": 0.636465743167353,
      "grad_norm": 0.23607792307243225,
      "learning_rate": 9.624174451834995e-05,
      "loss": 0.0681,
      "step": 850
    },
    {
      "epoch": 0.6439535754399102,
      "grad_norm": 0.2389419316523615,
      "learning_rate": 9.607434758459171e-05,
      "loss": 0.0695,
      "step": 860
    },
    {
      "epoch": 0.6514414077124673,
      "grad_norm": 0.23862300246236642,
      "learning_rate": 9.590345551619932e-05,
      "loss": 0.07,
      "step": 870
    },
    {
      "epoch": 0.6589292399850243,
      "grad_norm": 0.20149375846404521,
      "learning_rate": 9.572908127680266e-05,
      "loss": 0.0706,
      "step": 880
    },
    {
      "epoch": 0.6664170722575814,
      "grad_norm": 0.2527613743857202,
      "learning_rate": 9.555123809418409e-05,
      "loss": 0.0656,
      "step": 890
    },
    {
      "epoch": 0.6739049045301385,
      "grad_norm": 0.19023688910634745,
      "learning_rate": 9.536993945927512e-05,
      "loss": 0.0677,
      "step": 900
    },
    {
      "epoch": 0.6813927368026956,
      "grad_norm": 0.19434033014059127,
      "learning_rate": 9.518519912513293e-05,
      "loss": 0.0668,
      "step": 910
    },
    {
      "epoch": 0.6888805690752527,
      "grad_norm": 0.20973163672028308,
      "learning_rate": 9.499703110589717e-05,
      "loss": 0.0695,
      "step": 920
    },
    {
      "epoch": 0.6963684013478099,
      "grad_norm": 0.2176088319990617,
      "learning_rate": 9.480544967572677e-05,
      "loss": 0.0712,
      "step": 930
    },
    {
      "epoch": 0.7038562336203669,
      "grad_norm": 0.17990440150016457,
      "learning_rate": 9.461046936771722e-05,
      "loss": 0.0678,
      "step": 940
    },
    {
      "epoch": 0.711344065892924,
      "grad_norm": 0.21040180826019697,
      "learning_rate": 9.441210497279801e-05,
      "loss": 0.0626,
      "step": 950
    },
    {
      "epoch": 0.7188318981654811,
      "grad_norm": 0.1931075127878621,
      "learning_rate": 9.42103715386107e-05,
      "loss": 0.0677,
      "step": 960
    },
    {
      "epoch": 0.7263197304380382,
      "grad_norm": 0.2235122799214446,
      "learning_rate": 9.400528436836736e-05,
      "loss": 0.0671,
      "step": 970
    },
    {
      "epoch": 0.7338075627105953,
      "grad_norm": 0.19271593643612472,
      "learning_rate": 9.379685901968975e-05,
      "loss": 0.0662,
      "step": 980
    },
    {
      "epoch": 0.7412953949831523,
      "grad_norm": 0.2193431299334031,
      "learning_rate": 9.358511130342906e-05,
      "loss": 0.0663,
      "step": 990
    },
    {
      "epoch": 0.7487832272557094,
      "grad_norm": 0.23257972560261372,
      "learning_rate": 9.337005728246663e-05,
      "loss": 0.0637,
      "step": 1000
    },
    {
      "epoch": 0.7562710595282666,
      "grad_norm": 0.22803768088550053,
      "learning_rate": 9.315171327049536e-05,
      "loss": 0.075,
      "step": 1010
    },
    {
      "epoch": 0.7637588918008237,
      "grad_norm": 0.2215333341179134,
      "learning_rate": 9.29300958307822e-05,
      "loss": 0.0644,
      "step": 1020
    },
    {
      "epoch": 0.7712467240733808,
      "grad_norm": 0.22580378867591394,
      "learning_rate": 9.270522177491163e-05,
      "loss": 0.0733,
      "step": 1030
    },
    {
      "epoch": 0.7787345563459378,
      "grad_norm": 0.20417546791462604,
      "learning_rate": 9.247710816151051e-05,
      "loss": 0.071,
      "step": 1040
    },
    {
      "epoch": 0.7862223886184949,
      "grad_norm": 0.20628368369006495,
      "learning_rate": 9.224577229495388e-05,
      "loss": 0.0682,
      "step": 1050
    },
    {
      "epoch": 0.793710220891052,
      "grad_norm": 0.2011478951221961,
      "learning_rate": 9.201123172405232e-05,
      "loss": 0.0626,
      "step": 1060
    },
    {
      "epoch": 0.8011980531636091,
      "grad_norm": 0.19746597755277978,
      "learning_rate": 9.17735042407208e-05,
      "loss": 0.0667,
      "step": 1070
    },
    {
      "epoch": 0.8086858854361663,
      "grad_norm": 0.21414205520075238,
      "learning_rate": 9.153260787862885e-05,
      "loss": 0.0646,
      "step": 1080
    },
    {
      "epoch": 0.8161737177087234,
      "grad_norm": 0.15565107545645265,
      "learning_rate": 9.128856091183271e-05,
      "loss": 0.0678,
      "step": 1090
    },
    {
      "epoch": 0.8236615499812804,
      "grad_norm": 0.21646261042087242,
      "learning_rate": 9.104138185338902e-05,
      "loss": 0.0632,
      "step": 1100
    },
    {
      "epoch": 0.8311493822538375,
      "grad_norm": 0.18715786997311748,
      "learning_rate": 9.079108945395044e-05,
      "loss": 0.0678,
      "step": 1110
    },
    {
      "epoch": 0.8386372145263946,
      "grad_norm": 0.17471623747151258,
      "learning_rate": 9.053770270034326e-05,
      "loss": 0.0647,
      "step": 1120
    },
    {
      "epoch": 0.8461250467989517,
      "grad_norm": 0.22668341443231177,
      "learning_rate": 9.028124081412706e-05,
      "loss": 0.0627,
      "step": 1130
    },
    {
      "epoch": 0.8536128790715088,
      "grad_norm": 0.21046398460979554,
      "learning_rate": 9.002172325013667e-05,
      "loss": 0.0686,
      "step": 1140
    },
    {
      "epoch": 0.8611007113440659,
      "grad_norm": 0.17012646299138967,
      "learning_rate": 8.975916969500626e-05,
      "loss": 0.0624,
      "step": 1150
    },
    {
      "epoch": 0.868588543616623,
      "grad_norm": 0.23699768174179325,
      "learning_rate": 8.9493600065676e-05,
      "loss": 0.0673,
      "step": 1160
    },
    {
      "epoch": 0.8760763758891801,
      "grad_norm": 0.16789215439560068,
      "learning_rate": 8.922503450788113e-05,
      "loss": 0.0605,
      "step": 1170
    },
    {
      "epoch": 0.8835642081617372,
      "grad_norm": 0.2123591617522354,
      "learning_rate": 8.895349339462385e-05,
      "loss": 0.0669,
      "step": 1180
    },
    {
      "epoch": 0.8910520404342943,
      "grad_norm": 0.20360725764579618,
      "learning_rate": 8.867899732462772e-05,
      "loss": 0.0633,
      "step": 1190
    },
    {
      "epoch": 0.8985398727068513,
      "grad_norm": 0.1805667081038246,
      "learning_rate": 8.84015671207751e-05,
      "loss": 0.0632,
      "step": 1200
    },
    {
      "epoch": 0.9060277049794084,
      "grad_norm": 0.20183673067037552,
      "learning_rate": 8.812122382852766e-05,
      "loss": 0.0634,
      "step": 1210
    },
    {
      "epoch": 0.9135155372519655,
      "grad_norm": 0.1517899965193273,
      "learning_rate": 8.783798871432973e-05,
      "loss": 0.0666,
      "step": 1220
    },
    {
      "epoch": 0.9210033695245227,
      "grad_norm": 0.20327122736101633,
      "learning_rate": 8.755188326399524e-05,
      "loss": 0.0634,
      "step": 1230
    },
    {
      "epoch": 0.9284912017970798,
      "grad_norm": 0.20591409722011725,
      "learning_rate": 8.726292918107771e-05,
      "loss": 0.0608,
      "step": 1240
    },
    {
      "epoch": 0.9359790340696369,
      "grad_norm": 0.20751997338052733,
      "learning_rate": 8.697114838522383e-05,
      "loss": 0.0637,
      "step": 1250
    },
    {
      "epoch": 0.9434668663421939,
      "grad_norm": 0.16317986273598561,
      "learning_rate": 8.667656301051082e-05,
      "loss": 0.0586,
      "step": 1260
    },
    {
      "epoch": 0.950954698614751,
      "grad_norm": 0.18323199889603028,
      "learning_rate": 8.637919540376722e-05,
      "loss": 0.0596,
      "step": 1270
    },
    {
      "epoch": 0.9584425308873081,
      "grad_norm": 0.1684125497731882,
      "learning_rate": 8.607906812287774e-05,
      "loss": 0.0615,
      "step": 1280
    },
    {
      "epoch": 0.9659303631598652,
      "grad_norm": 0.17233264050313132,
      "learning_rate": 8.577620393507206e-05,
      "loss": 0.066,
      "step": 1290
    },
    {
      "epoch": 0.9734181954324224,
      "grad_norm": 0.2198495569711333,
      "learning_rate": 8.547062581519775e-05,
      "loss": 0.0598,
      "step": 1300
    },
    {
      "epoch": 0.9809060277049794,
      "grad_norm": 0.22593626470037279,
      "learning_rate": 8.516235694397742e-05,
      "loss": 0.0607,
      "step": 1310
    },
    {
      "epoch": 0.9883938599775365,
      "grad_norm": 0.1867216962020902,
      "learning_rate": 8.485142070625022e-05,
      "loss": 0.0591,
      "step": 1320
    },
    {
      "epoch": 0.9958816922500936,
      "grad_norm": 0.19545763664534663,
      "learning_rate": 8.453784068919799e-05,
      "loss": 0.0616,
      "step": 1330
    },
    {
      "epoch": 1.0029951329090228,
      "grad_norm": 0.1458345508163628,
      "learning_rate": 8.422164068055588e-05,
      "loss": 0.0605,
      "step": 1340
    },
    {
      "epoch": 1.0104829651815799,
      "grad_norm": 0.17277222679668197,
      "learning_rate": 8.39028446668079e-05,
      "loss": 0.0602,
      "step": 1350
    },
    {
      "epoch": 1.017970797454137,
      "grad_norm": 0.20087066484955088,
      "learning_rate": 8.358147683136732e-05,
      "loss": 0.0593,
      "step": 1360
    },
    {
      "epoch": 1.025458629726694,
      "grad_norm": 0.18638991412200276,
      "learning_rate": 8.325756155274215e-05,
      "loss": 0.0519,
      "step": 1370
    },
    {
      "epoch": 1.0329464619992512,
      "grad_norm": 0.1962633723852575,
      "learning_rate": 8.293112340268585e-05,
      "loss": 0.062,
      "step": 1380
    },
    {
      "epoch": 1.0404342942718083,
      "grad_norm": 0.19843118553288236,
      "learning_rate": 8.26021871443333e-05,
      "loss": 0.0563,
      "step": 1390
    },
    {
      "epoch": 1.0479221265443655,
      "grad_norm": 0.1629422981788852,
      "learning_rate": 8.227077773032235e-05,
      "loss": 0.0618,
      "step": 1400
    },
    {
      "epoch": 1.0554099588169226,
      "grad_norm": 0.1951848794145327,
      "learning_rate": 8.193692030090088e-05,
      "loss": 0.0569,
      "step": 1410
    },
    {
      "epoch": 1.0628977910894797,
      "grad_norm": 0.20582465390029198,
      "learning_rate": 8.160064018201984e-05,
      "loss": 0.0579,
      "step": 1420
    },
    {
      "epoch": 1.0703856233620366,
      "grad_norm": 0.18246212620225555,
      "learning_rate": 8.126196288341187e-05,
      "loss": 0.0581,
      "step": 1430
    },
    {
      "epoch": 1.0778734556345937,
      "grad_norm": 0.2068065971306317,
      "learning_rate": 8.092091409665632e-05,
      "loss": 0.0562,
      "step": 1440
    },
    {
      "epoch": 1.0853612879071508,
      "grad_norm": 0.21273256617571976,
      "learning_rate": 8.057751969323023e-05,
      "loss": 0.056,
      "step": 1450
    },
    {
      "epoch": 1.092849120179708,
      "grad_norm": 0.21529050708773276,
      "learning_rate": 8.023180572254585e-05,
      "loss": 0.0558,
      "step": 1460
    },
    {
      "epoch": 1.100336952452265,
      "grad_norm": 0.18123057994667555,
      "learning_rate": 7.988379840997443e-05,
      "loss": 0.0556,
      "step": 1470
    },
    {
      "epoch": 1.1078247847248222,
      "grad_norm": 0.18954639129972298,
      "learning_rate": 7.953352415485693e-05,
      "loss": 0.0599,
      "step": 1480
    },
    {
      "epoch": 1.1153126169973793,
      "grad_norm": 0.22958637872474685,
      "learning_rate": 7.918100952850136e-05,
      "loss": 0.0576,
      "step": 1490
    },
    {
      "epoch": 1.1228004492699364,
      "grad_norm": 0.1565733099310718,
      "learning_rate": 7.882628127216712e-05,
      "loss": 0.0589,
      "step": 1500
    },
    {
      "epoch": 1.1302882815424935,
      "grad_norm": 0.19566633399618433,
      "learning_rate": 7.846936629503639e-05,
      "loss": 0.055,
      "step": 1510
    },
    {
      "epoch": 1.1377761138150506,
      "grad_norm": 0.16962873190069117,
      "learning_rate": 7.811029167217291e-05,
      "loss": 0.0578,
      "step": 1520
    },
    {
      "epoch": 1.1452639460876077,
      "grad_norm": 0.20956788911274543,
      "learning_rate": 7.774908464246815e-05,
      "loss": 0.0576,
      "step": 1530
    },
    {
      "epoch": 1.1527517783601646,
      "grad_norm": 0.17640496035740524,
      "learning_rate": 7.73857726065748e-05,
      "loss": 0.0555,
      "step": 1540
    },
    {
      "epoch": 1.1602396106327217,
      "grad_norm": 0.18056890824009236,
      "learning_rate": 7.702038312482847e-05,
      "loss": 0.0584,
      "step": 1550
    },
    {
      "epoch": 1.1677274429052789,
      "grad_norm": 0.17674949324646186,
      "learning_rate": 7.665294391515675e-05,
      "loss": 0.058,
      "step": 1560
    },
    {
      "epoch": 1.175215275177836,
      "grad_norm": 0.18509939619590732,
      "learning_rate": 7.62834828509768e-05,
      "loss": 0.0586,
      "step": 1570
    },
    {
      "epoch": 1.182703107450393,
      "grad_norm": 0.20845489202306156,
      "learning_rate": 7.591202795908068e-05,
      "loss": 0.0555,
      "step": 1580
    },
    {
      "epoch": 1.1901909397229502,
      "grad_norm": 0.1960426512274284,
      "learning_rate": 7.553860741750945e-05,
      "loss": 0.0593,
      "step": 1590
    },
    {
      "epoch": 1.1976787719955073,
      "grad_norm": 0.17964570308316288,
      "learning_rate": 7.516324955341556e-05,
      "loss": 0.059,
      "step": 1600
    },
    {
      "epoch": 1.2051666042680644,
      "grad_norm": 0.20025465084139304,
      "learning_rate": 7.478598284091401e-05,
      "loss": 0.0556,
      "step": 1610
    },
    {
      "epoch": 1.2126544365406215,
      "grad_norm": 0.198780283696502,
      "learning_rate": 7.440683589892231e-05,
      "loss": 0.0546,
      "step": 1620
    },
    {
      "epoch": 1.2201422688131787,
      "grad_norm": 0.18972532086395763,
      "learning_rate": 7.402583748898952e-05,
      "loss": 0.0583,
      "step": 1630
    },
    {
      "epoch": 1.2276301010857358,
      "grad_norm": 0.15638560418255346,
      "learning_rate": 7.36430165131144e-05,
      "loss": 0.0543,
      "step": 1640
    },
    {
      "epoch": 1.2351179333582927,
      "grad_norm": 0.17653211493609358,
      "learning_rate": 7.325840201155306e-05,
      "loss": 0.0569,
      "step": 1650
    },
    {
      "epoch": 1.2426057656308498,
      "grad_norm": 0.16713105132341416,
      "learning_rate": 7.287202316061582e-05,
      "loss": 0.0568,
      "step": 1660
    },
    {
      "epoch": 1.250093597903407,
      "grad_norm": 0.17213821019693396,
      "learning_rate": 7.248390927045411e-05,
      "loss": 0.0601,
      "step": 1670
    },
    {
      "epoch": 1.257581430175964,
      "grad_norm": 0.17376699828943107,
      "learning_rate": 7.209408978283696e-05,
      "loss": 0.0582,
      "step": 1680
    },
    {
      "epoch": 1.2650692624485211,
      "grad_norm": 0.1822157031820032,
      "learning_rate": 7.170259426891756e-05,
      "loss": 0.0587,
      "step": 1690
    },
    {
      "epoch": 1.2725570947210783,
      "grad_norm": 0.17415067392942807,
      "learning_rate": 7.130945242699018e-05,
      "loss": 0.0593,
      "step": 1700
    },
    {
      "epoch": 1.2800449269936354,
      "grad_norm": 0.21957293957341026,
      "learning_rate": 7.091469408023707e-05,
      "loss": 0.0546,
      "step": 1710
    },
    {
      "epoch": 1.2875327592661925,
      "grad_norm": 0.18554331463061433,
      "learning_rate": 7.051834917446634e-05,
      "loss": 0.0552,
      "step": 1720
    },
    {
      "epoch": 1.2950205915387496,
      "grad_norm": 0.1643557612698287,
      "learning_rate": 7.012044777584014e-05,
      "loss": 0.0546,
      "step": 1730
    },
    {
      "epoch": 1.3025084238113065,
      "grad_norm": 0.16892738839964663,
      "learning_rate": 6.972102006859404e-05,
      "loss": 0.0523,
      "step": 1740
    },
    {
      "epoch": 1.3099962560838638,
      "grad_norm": 0.20866088052421292,
      "learning_rate": 6.932009635274716e-05,
      "loss": 0.0545,
      "step": 1750
    },
    {
      "epoch": 1.3174840883564207,
      "grad_norm": 0.18759972688078458,
      "learning_rate": 6.891770704180372e-05,
      "loss": 0.052,
      "step": 1760
    },
    {
      "epoch": 1.3249719206289778,
      "grad_norm": 0.2680191787182651,
      "learning_rate": 6.85138826604459e-05,
      "loss": 0.054,
      "step": 1770
    },
    {
      "epoch": 1.332459752901535,
      "grad_norm": 0.16010681696110318,
      "learning_rate": 6.81086538422183e-05,
      "loss": 0.057,
      "step": 1780
    },
    {
      "epoch": 1.339947585174092,
      "grad_norm": 0.15793316488295994,
      "learning_rate": 6.770205132720411e-05,
      "loss": 0.0561,
      "step": 1790
    },
    {
      "epoch": 1.3474354174466492,
      "grad_norm": 0.14596065669468614,
      "learning_rate": 6.72941059596932e-05,
      "loss": 0.0571,
      "step": 1800
    },
    {
      "epoch": 1.3549232497192063,
      "grad_norm": 0.14830938408752606,
      "learning_rate": 6.688484868584234e-05,
      "loss": 0.0551,
      "step": 1810
    },
    {
      "epoch": 1.3624110819917634,
      "grad_norm": 0.17596854051815333,
      "learning_rate": 6.647431055132762e-05,
      "loss": 0.0548,
      "step": 1820
    },
    {
      "epoch": 1.3698989142643205,
      "grad_norm": 0.17728761798032708,
      "learning_rate": 6.60625226989894e-05,
      "loss": 0.0552,
      "step": 1830
    },
    {
      "epoch": 1.3773867465368776,
      "grad_norm": 0.1990906686070289,
      "learning_rate": 6.564951636646995e-05,
      "loss": 0.0547,
      "step": 1840
    },
    {
      "epoch": 1.3848745788094345,
      "grad_norm": 0.23097385919235336,
      "learning_rate": 6.52353228838436e-05,
      "loss": 0.0571,
      "step": 1850
    },
    {
      "epoch": 1.3923624110819919,
      "grad_norm": 0.1711657251083468,
      "learning_rate": 6.481997367124025e-05,
      "loss": 0.0558,
      "step": 1860
    },
    {
      "epoch": 1.3998502433545488,
      "grad_norm": 0.16433553417335892,
      "learning_rate": 6.440350023646189e-05,
      "loss": 0.0533,
      "step": 1870
    },
    {
      "epoch": 1.4073380756271059,
      "grad_norm": 0.21980680821306048,
      "learning_rate": 6.39859341725923e-05,
      "loss": 0.0554,
      "step": 1880
    },
    {
      "epoch": 1.414825907899663,
      "grad_norm": 0.15890413332865777,
      "learning_rate": 6.356730715560065e-05,
      "loss": 0.0571,
      "step": 1890
    },
    {
      "epoch": 1.4223137401722201,
      "grad_norm": 0.1685392795506407,
      "learning_rate": 6.314765094193848e-05,
      "loss": 0.0565,
      "step": 1900
    },
    {
      "epoch": 1.4298015724447772,
      "grad_norm": 0.18678371644239,
      "learning_rate": 6.272699736613067e-05,
      "loss": 0.0554,
      "step": 1910
    },
    {
      "epoch": 1.4372894047173344,
      "grad_norm": 0.27172825140021767,
      "learning_rate": 6.230537833836066e-05,
      "loss": 0.0556,
      "step": 1920
    },
    {
      "epoch": 1.4447772369898915,
      "grad_norm": 0.16671181608502114,
      "learning_rate": 6.188282584204967e-05,
      "loss": 0.0552,
      "step": 1930
    },
    {
      "epoch": 1.4522650692624486,
      "grad_norm": 0.14646047945479107,
      "learning_rate": 6.145937193143054e-05,
      "loss": 0.0541,
      "step": 1940
    },
    {
      "epoch": 1.4597529015350057,
      "grad_norm": 0.15859657911283845,
      "learning_rate": 6.103504872911606e-05,
      "loss": 0.0535,
      "step": 1950
    },
    {
      "epoch": 1.4672407338075626,
      "grad_norm": 0.2646813588214359,
      "learning_rate": 6.0609888423662344e-05,
      "loss": 0.0526,
      "step": 1960
    },
    {
      "epoch": 1.47472856608012,
      "grad_norm": 0.15657654915008398,
      "learning_rate": 6.0183923267126864e-05,
      "loss": 0.0555,
      "step": 1970
    },
    {
      "epoch": 1.4822163983526768,
      "grad_norm": 0.17748051220539843,
      "learning_rate": 5.975718557262205e-05,
      "loss": 0.0568,
      "step": 1980
    },
    {
      "epoch": 1.489704230625234,
      "grad_norm": 0.22218080943289745,
      "learning_rate": 5.9329707711863905e-05,
      "loss": 0.0558,
      "step": 1990
    },
    {
      "epoch": 1.497192062897791,
      "grad_norm": 0.1487458828521303,
      "learning_rate": 5.89015221127164e-05,
      "loss": 0.0513,
      "step": 2000
    },
    {
      "epoch": 1.5046798951703482,
      "grad_norm": 0.16565658928934107,
      "learning_rate": 5.847266125673155e-05,
      "loss": 0.0522,
      "step": 2010
    },
    {
      "epoch": 1.5121677274429053,
      "grad_norm": 0.18054084564967765,
      "learning_rate": 5.80431576766854e-05,
      "loss": 0.0562,
      "step": 2020
    },
    {
      "epoch": 1.5196555597154624,
      "grad_norm": 0.17920824595499893,
      "learning_rate": 5.761304395411011e-05,
      "loss": 0.0557,
      "step": 2030
    },
    {
      "epoch": 1.5271433919880195,
      "grad_norm": 0.18009326159292638,
      "learning_rate": 5.7182352716822406e-05,
      "loss": 0.0527,
      "step": 2040
    },
    {
      "epoch": 1.5346312242605764,
      "grad_norm": 0.18889321563649975,
      "learning_rate": 5.675111663644845e-05,
      "loss": 0.0554,
      "step": 2050
    },
    {
      "epoch": 1.5421190565331337,
      "grad_norm": 0.17356889885041982,
      "learning_rate": 5.6319368425945426e-05,
      "loss": 0.0581,
      "step": 2060
    },
    {
      "epoch": 1.5496068888056906,
      "grad_norm": 0.1912645166793255,
      "learning_rate": 5.588714083711999e-05,
      "loss": 0.0554,
      "step": 2070
    },
    {
      "epoch": 1.557094721078248,
      "grad_norm": 0.1849196677423877,
      "learning_rate": 5.5454466658143756e-05,
      "loss": 0.0529,
      "step": 2080
    },
    {
      "epoch": 1.5645825533508049,
      "grad_norm": 0.1670315180683356,
      "learning_rate": 5.502137871106603e-05,
      "loss": 0.0573,
      "step": 2090
    },
    {
      "epoch": 1.572070385623362,
      "grad_norm": 0.14282317454473972,
      "learning_rate": 5.458790984932398e-05,
      "loss": 0.053,
      "step": 2100
    },
    {
      "epoch": 1.579558217895919,
      "grad_norm": 0.2042193421507061,
      "learning_rate": 5.4154092955250414e-05,
      "loss": 0.0511,
      "step": 2110
    },
    {
      "epoch": 1.5870460501684762,
      "grad_norm": 0.16726655914527416,
      "learning_rate": 5.3719960937579405e-05,
      "loss": 0.0548,
      "step": 2120
    },
    {
      "epoch": 1.5945338824410333,
      "grad_norm": 0.17350625231377492,
      "learning_rate": 5.328554672894982e-05,
      "loss": 0.058,
      "step": 2130
    },
    {
      "epoch": 1.6020217147135905,
      "grad_norm": 0.1854135033438716,
      "learning_rate": 5.285088328340715e-05,
      "loss": 0.0541,
      "step": 2140
    },
    {
      "epoch": 1.6095095469861476,
      "grad_norm": 0.1692698833155081,
      "learning_rate": 5.241600357390364e-05,
      "loss": 0.0518,
      "step": 2150
    },
    {
      "epoch": 1.6169973792587045,
      "grad_norm": 0.14038171067019434,
      "learning_rate": 5.198094058979701e-05,
      "loss": 0.0518,
      "step": 2160
    },
    {
      "epoch": 1.6244852115312618,
      "grad_norm": 0.24611842509291687,
      "learning_rate": 5.154572733434795e-05,
      "loss": 0.0551,
      "step": 2170
    },
    {
      "epoch": 1.6319730438038187,
      "grad_norm": 0.19567719335435355,
      "learning_rate": 5.111039682221649e-05,
      "loss": 0.0532,
      "step": 2180
    },
    {
      "epoch": 1.639460876076376,
      "grad_norm": 0.17575869358237495,
      "learning_rate": 5.067498207695762e-05,
      "loss": 0.0609,
      "step": 2190
    },
    {
      "epoch": 1.646948708348933,
      "grad_norm": 0.14146165924649476,
      "learning_rate": 5.0239516128516084e-05,
      "loss": 0.0576,
      "step": 2200
    },
    {
      "epoch": 1.65443654062149,
      "grad_norm": 0.1890173785452179,
      "learning_rate": 4.9804032010720896e-05,
      "loss": 0.0563,
      "step": 2210
    },
    {
      "epoch": 1.6619243728940472,
      "grad_norm": 0.16736504723532622,
      "learning_rate": 4.936856275877932e-05,
      "loss": 0.0549,
      "step": 2220
    },
    {
      "epoch": 1.6694122051666043,
      "grad_norm": 0.15841377727242312,
      "learning_rate": 4.893314140677093e-05,
      "loss": 0.054,
      "step": 2230
    },
    {
      "epoch": 1.6769000374391614,
      "grad_norm": 0.1633093206055001,
      "learning_rate": 4.849780098514169e-05,
      "loss": 0.0519,
      "step": 2240
    },
    {
      "epoch": 1.6843878697117185,
      "grad_norm": 0.1689307978087843,
      "learning_rate": 4.806257451819829e-05,
      "loss": 0.0494,
      "step": 2250
    },
    {
      "epoch": 1.6918757019842756,
      "grad_norm": 0.17161653024997617,
      "learning_rate": 4.762749502160297e-05,
      "loss": 0.0562,
      "step": 2260
    },
    {
      "epoch": 1.6993635342568325,
      "grad_norm": 0.19733118786506576,
      "learning_rate": 4.719259549986903e-05,
      "loss": 0.0511,
      "step": 2270
    },
    {
      "epoch": 1.7068513665293898,
      "grad_norm": 0.17697750925546946,
      "learning_rate": 4.6757908943857145e-05,
      "loss": 0.0509,
      "step": 2280
    },
    {
      "epoch": 1.7143391988019467,
      "grad_norm": 0.16570100168261587,
      "learning_rate": 4.632346832827262e-05,
      "loss": 0.0526,
      "step": 2290
    },
    {
      "epoch": 1.721827031074504,
      "grad_norm": 0.153737753994631,
      "learning_rate": 4.5889306609164206e-05,
      "loss": 0.0505,
      "step": 2300
    },
    {
      "epoch": 1.729314863347061,
      "grad_norm": 0.1827943153857043,
      "learning_rate": 4.545545672142386e-05,
      "loss": 0.0506,
      "step": 2310
    },
    {
      "epoch": 1.736802695619618,
      "grad_norm": 0.16801707327190182,
      "learning_rate": 4.502195157628853e-05,
      "loss": 0.0481,
      "step": 2320
    },
    {
      "epoch": 1.7442905278921752,
      "grad_norm": 0.1521792538178683,
      "learning_rate": 4.4588824058843373e-05,
      "loss": 0.0498,
      "step": 2330
    },
    {
      "epoch": 1.7517783601647323,
      "grad_norm": 0.14349929496939967,
      "learning_rate": 4.415610702552734e-05,
      "loss": 0.0523,
      "step": 2340
    },
    {
      "epoch": 1.7592661924372894,
      "grad_norm": 0.14073355114096842,
      "learning_rate": 4.372383330164061e-05,
      "loss": 0.0476,
      "step": 2350
    },
    {
      "epoch": 1.7667540247098465,
      "grad_norm": 0.15490034599725905,
      "learning_rate": 4.329203567885456e-05,
      "loss": 0.0522,
      "step": 2360
    },
    {
      "epoch": 1.7742418569824037,
      "grad_norm": 0.1802045507710863,
      "learning_rate": 4.286074691272415e-05,
      "loss": 0.0556,
      "step": 2370
    },
    {
      "epoch": 1.7817296892549606,
      "grad_norm": 0.1727686868218979,
      "learning_rate": 4.242999972020324e-05,
      "loss": 0.0528,
      "step": 2380
    },
    {
      "epoch": 1.789217521527518,
      "grad_norm": 0.1640447245403985,
      "learning_rate": 4.1999826777162685e-05,
      "loss": 0.0496,
      "step": 2390
    },
    {
      "epoch": 1.7967053538000748,
      "grad_norm": 0.1589915282875347,
      "learning_rate": 4.1570260715911605e-05,
      "loss": 0.0563,
      "step": 2400
    },
    {
      "epoch": 1.8041931860726321,
      "grad_norm": 0.18443258390300196,
      "learning_rate": 4.114133412272187e-05,
      "loss": 0.0533,
      "step": 2410
    },
    {
      "epoch": 1.811681018345189,
      "grad_norm": 0.15973100697474288,
      "learning_rate": 4.071307953535627e-05,
      "loss": 0.0539,
      "step": 2420
    },
    {
      "epoch": 1.8191688506177461,
      "grad_norm": 0.1673833140505875,
      "learning_rate": 4.0285529440600164e-05,
      "loss": 0.0537,
      "step": 2430
    },
    {
      "epoch": 1.8266566828903033,
      "grad_norm": 0.1838457337406938,
      "learning_rate": 3.9858716271797086e-05,
      "loss": 0.0533,
      "step": 2440
    },
    {
      "epoch": 1.8341445151628604,
      "grad_norm": 0.15434370259181243,
      "learning_rate": 3.943267240638844e-05,
      "loss": 0.0514,
      "step": 2450
    },
    {
      "epoch": 1.8416323474354175,
      "grad_norm": 0.17239007633006367,
      "learning_rate": 3.9007430163457346e-05,
      "loss": 0.0537,
      "step": 2460
    },
    {
      "epoch": 1.8491201797079744,
      "grad_norm": 0.14609830496620974,
      "learning_rate": 3.858302180127701e-05,
      "loss": 0.0503,
      "step": 2470
    },
    {
      "epoch": 1.8566080119805317,
      "grad_norm": 0.19774455362956553,
      "learning_rate": 3.815947951486358e-05,
      "loss": 0.0504,
      "step": 2480
    },
    {
      "epoch": 1.8640958442530886,
      "grad_norm": 0.16940685156170898,
      "learning_rate": 3.773683543353395e-05,
      "loss": 0.0507,
      "step": 2490
    },
    {
      "epoch": 1.871583676525646,
      "grad_norm": 0.24204249703195194,
      "learning_rate": 3.731512161846846e-05,
      "loss": 0.051,
      "step": 2500
    },
    {
      "epoch": 1.8790715087982028,
      "grad_norm": 0.17846183256140227,
      "learning_rate": 3.6894370060278796e-05,
      "loss": 0.0537,
      "step": 2510
    },
    {
      "epoch": 1.8865593410707602,
      "grad_norm": 0.15063718760659123,
      "learning_rate": 3.6474612676581096e-05,
      "loss": 0.0508,
      "step": 2520
    },
    {
      "epoch": 1.894047173343317,
      "grad_norm": 0.17430987189899813,
      "learning_rate": 3.605588130957496e-05,
      "loss": 0.0502,
      "step": 2530
    },
    {
      "epoch": 1.9015350056158742,
      "grad_norm": 0.1463196280909664,
      "learning_rate": 3.563820772362775e-05,
      "loss": 0.0521,
      "step": 2540
    },
    {
      "epoch": 1.9090228378884313,
      "grad_norm": 0.16550314488318485,
      "learning_rate": 3.5221623602865086e-05,
      "loss": 0.0541,
      "step": 2550
    },
    {
      "epoch": 1.9165106701609884,
      "grad_norm": 0.17294499174259084,
      "learning_rate": 3.480616054876725e-05,
      "loss": 0.0526,
      "step": 2560
    },
    {
      "epoch": 1.9239985024335455,
      "grad_norm": 0.16913780506057913,
      "learning_rate": 3.439185007777206e-05,
      "loss": 0.054,
      "step": 2570
    },
    {
      "epoch": 1.9314863347061024,
      "grad_norm": 0.17763541882102668,
      "learning_rate": 3.3978723618883976e-05,
      "loss": 0.0555,
      "step": 2580
    },
    {
      "epoch": 1.9389741669786598,
      "grad_norm": 0.17524780966578954,
      "learning_rate": 3.3566812511290044e-05,
      "loss": 0.0503,
      "step": 2590
    },
    {
      "epoch": 1.9464619992512167,
      "grad_norm": 0.1770294270748269,
      "learning_rate": 3.3156148001982386e-05,
      "loss": 0.0488,
      "step": 2600
    },
    {
      "epoch": 1.953949831523774,
      "grad_norm": 0.1892529180535848,
      "learning_rate": 3.2746761243388e-05,
      "loss": 0.0523,
      "step": 2610
    },
    {
      "epoch": 1.9614376637963309,
      "grad_norm": 0.2123709690578222,
      "learning_rate": 3.233868329100555e-05,
      "loss": 0.0548,
      "step": 2620
    },
    {
      "epoch": 1.968925496068888,
      "grad_norm": 0.1924197633976182,
      "learning_rate": 3.193194510104949e-05,
      "loss": 0.0484,
      "step": 2630
    },
    {
      "epoch": 1.9764133283414451,
      "grad_norm": 0.17258637877424635,
      "learning_rate": 3.1526577528101774e-05,
      "loss": 0.0526,
      "step": 2640
    },
    {
      "epoch": 1.9839011606140022,
      "grad_norm": 0.19140963914978418,
      "learning_rate": 3.1122611322771346e-05,
      "loss": 0.055,
      "step": 2650
    },
    {
      "epoch": 1.9913889928865594,
      "grad_norm": 0.18030176927055025,
      "learning_rate": 3.072007712936137e-05,
      "loss": 0.0498,
      "step": 2660
    },
    {
      "epoch": 1.9988768251591165,
      "grad_norm": 0.16094295536205477,
      "learning_rate": 3.0319005483544583e-05,
      "loss": 0.0512,
      "step": 2670
    },
    {
      "epoch": 2.0059902658180455,
      "grad_norm": 0.13590360413634753,
      "learning_rate": 2.991942681004699e-05,
      "loss": 0.0449,
      "step": 2680
    },
    {
      "epoch": 2.013478098090603,
      "grad_norm": 0.17706446798430356,
      "learning_rate": 2.9521371420339804e-05,
      "loss": 0.0468,
      "step": 2690
    },
    {
      "epoch": 2.0209659303631597,
      "grad_norm": 0.17582786903321687,
      "learning_rate": 2.9124869510340124e-05,
      "loss": 0.0476,
      "step": 2700
    },
    {
      "epoch": 2.028453762635717,
      "grad_norm": 0.16932416800225658,
      "learning_rate": 2.8729951158120218e-05,
      "loss": 0.0468,
      "step": 2710
    },
    {
      "epoch": 2.035941594908274,
      "grad_norm": 0.1632202879268178,
      "learning_rate": 2.8336646321625954e-05,
      "loss": 0.0494,
      "step": 2720
    },
    {
      "epoch": 2.0434294271808313,
      "grad_norm": 0.14971145919233778,
      "learning_rate": 2.7944984836404185e-05,
      "loss": 0.0452,
      "step": 2730
    },
    {
      "epoch": 2.050917259453388,
      "grad_norm": 0.19520771785283014,
      "learning_rate": 2.7554996413339473e-05,
      "loss": 0.0467,
      "step": 2740
    },
    {
      "epoch": 2.0584050917259455,
      "grad_norm": 0.17817082143019233,
      "learning_rate": 2.7166710636400234e-05,
      "loss": 0.0453,
      "step": 2750
    },
    {
      "epoch": 2.0658929239985024,
      "grad_norm": 0.18967102345524597,
      "learning_rate": 2.6780156960394586e-05,
      "loss": 0.046,
      "step": 2760
    },
    {
      "epoch": 2.0733807562710593,
      "grad_norm": 0.19173176581703474,
      "learning_rate": 2.6395364708735916e-05,
      "loss": 0.0487,
      "step": 2770
    },
    {
      "epoch": 2.0808685885436167,
      "grad_norm": 0.17050870113509517,
      "learning_rate": 2.6012363071218483e-05,
      "loss": 0.0498,
      "step": 2780
    },
    {
      "epoch": 2.0883564208161736,
      "grad_norm": 0.2028981424050354,
      "learning_rate": 2.5631181101803037e-05,
      "loss": 0.0453,
      "step": 2790
    },
    {
      "epoch": 2.095844253088731,
      "grad_norm": 0.15483697089996726,
      "learning_rate": 2.5251847716412958e-05,
      "loss": 0.0461,
      "step": 2800
    },
    {
      "epoch": 2.103332085361288,
      "grad_norm": 0.1790500468311653,
      "learning_rate": 2.487439169074063e-05,
      "loss": 0.0463,
      "step": 2810
    },
    {
      "epoch": 2.110819917633845,
      "grad_norm": 0.14962428759787552,
      "learning_rate": 2.4498841658064598e-05,
      "loss": 0.0417,
      "step": 2820
    },
    {
      "epoch": 2.118307749906402,
      "grad_norm": 0.17306834077878455,
      "learning_rate": 2.4125226107077482e-05,
      "loss": 0.0498,
      "step": 2830
    },
    {
      "epoch": 2.1257955821789594,
      "grad_norm": 0.19836893899791838,
      "learning_rate": 2.375357337972487e-05,
      "loss": 0.0475,
      "step": 2840
    },
    {
      "epoch": 2.1332834144515163,
      "grad_norm": 0.23284200779988629,
      "learning_rate": 2.338391166905533e-05,
      "loss": 0.0454,
      "step": 2850
    },
    {
      "epoch": 2.140771246724073,
      "grad_norm": 0.19465744129243207,
      "learning_rate": 2.3016269017081748e-05,
      "loss": 0.047,
      "step": 2860
    },
    {
      "epoch": 2.1482590789966305,
      "grad_norm": 0.14144911345982844,
      "learning_rate": 2.265067331265403e-05,
      "loss": 0.043,
      "step": 2870
    },
    {
      "epoch": 2.1557469112691874,
      "grad_norm": 0.17623574246185536,
      "learning_rate": 2.22871522893436e-05,
      "loss": 0.0484,
      "step": 2880
    },
    {
      "epoch": 2.1632347435417447,
      "grad_norm": 0.15532371157442637,
      "learning_rate": 2.1925733523339502e-05,
      "loss": 0.0484,
      "step": 2890
    },
    {
      "epoch": 2.1707225758143016,
      "grad_norm": 0.18313223295463002,
      "learning_rate": 2.1566444431356496e-05,
      "loss": 0.0455,
      "step": 2900
    },
    {
      "epoch": 2.178210408086859,
      "grad_norm": 0.21064993620172634,
      "learning_rate": 2.1209312268555333e-05,
      "loss": 0.0452,
      "step": 2910
    },
    {
      "epoch": 2.185698240359416,
      "grad_norm": 0.15882508037251025,
      "learning_rate": 2.085436412647514e-05,
      "loss": 0.0464,
      "step": 2920
    },
    {
      "epoch": 2.193186072631973,
      "grad_norm": 0.16526025564922142,
      "learning_rate": 2.050162693097837e-05,
      "loss": 0.0447,
      "step": 2930
    },
    {
      "epoch": 2.20067390490453,
      "grad_norm": 0.16754349097509375,
      "learning_rate": 2.0151127440208174e-05,
      "loss": 0.0448,
      "step": 2940
    },
    {
      "epoch": 2.2081617371770874,
      "grad_norm": 0.2253094639433509,
      "learning_rate": 1.9802892242558602e-05,
      "loss": 0.0439,
      "step": 2950
    },
    {
      "epoch": 2.2156495694496443,
      "grad_norm": 0.18061839607649405,
      "learning_rate": 1.945694775465766e-05,
      "loss": 0.0458,
      "step": 2960
    },
    {
      "epoch": 2.2231374017222016,
      "grad_norm": 0.16418326796996666,
      "learning_rate": 1.9113320219363356e-05,
      "loss": 0.0442,
      "step": 2970
    },
    {
      "epoch": 2.2306252339947585,
      "grad_norm": 0.18372691353819331,
      "learning_rate": 1.877203570377292e-05,
      "loss": 0.0486,
      "step": 2980
    },
    {
      "epoch": 2.2381130662673154,
      "grad_norm": 0.19466462442039856,
      "learning_rate": 1.8433120097245494e-05,
      "loss": 0.0439,
      "step": 2990
    },
    {
      "epoch": 2.2456008985398728,
      "grad_norm": 0.21835430942523573,
      "learning_rate": 1.8096599109438096e-05,
      "loss": 0.0474,
      "step": 3000
    },
    {
      "epoch": 2.2530887308124297,
      "grad_norm": 0.15495250727426818,
      "learning_rate": 1.7762498268355382e-05,
      "loss": 0.0441,
      "step": 3010
    },
    {
      "epoch": 2.260576563084987,
      "grad_norm": 0.18747643669345604,
      "learning_rate": 1.743084291841312e-05,
      "loss": 0.0466,
      "step": 3020
    },
    {
      "epoch": 2.268064395357544,
      "grad_norm": 0.19066805008393128,
      "learning_rate": 1.7101658218515572e-05,
      "loss": 0.0503,
      "step": 3030
    },
    {
      "epoch": 2.2755522276301012,
      "grad_norm": 0.16896570172925673,
      "learning_rate": 1.6774969140147008e-05,
      "loss": 0.0458,
      "step": 3040
    },
    {
      "epoch": 2.283040059902658,
      "grad_norm": 0.2124822789153048,
      "learning_rate": 1.645080046547739e-05,
      "loss": 0.0472,
      "step": 3050
    },
    {
      "epoch": 2.2905278921752155,
      "grad_norm": 0.17189974673217573,
      "learning_rate": 1.6129176785482393e-05,
      "loss": 0.0449,
      "step": 3060
    },
    {
      "epoch": 2.2980157244477724,
      "grad_norm": 0.20673051860377784,
      "learning_rate": 1.5810122498078063e-05,
      "loss": 0.0441,
      "step": 3070
    },
    {
      "epoch": 2.3055035567203293,
      "grad_norm": 0.15812389544606845,
      "learning_rate": 1.5493661806269938e-05,
      "loss": 0.0461,
      "step": 3080
    },
    {
      "epoch": 2.3129913889928866,
      "grad_norm": 0.15394090834650467,
      "learning_rate": 1.5179818716317096e-05,
      "loss": 0.0474,
      "step": 3090
    },
    {
      "epoch": 2.3204792212654435,
      "grad_norm": 0.1974968139331501,
      "learning_rate": 1.4868617035910997e-05,
      "loss": 0.046,
      "step": 3100
    },
    {
      "epoch": 2.327967053538001,
      "grad_norm": 0.1880087244183989,
      "learning_rate": 1.45600803723696e-05,
      "loss": 0.045,
      "step": 3110
    },
    {
      "epoch": 2.3354548858105577,
      "grad_norm": 0.21993507692707145,
      "learning_rate": 1.4254232130846418e-05,
      "loss": 0.0456,
      "step": 3120
    },
    {
      "epoch": 2.342942718083115,
      "grad_norm": 0.14957358041864094,
      "learning_rate": 1.39510955125551e-05,
      "loss": 0.0442,
      "step": 3130
    },
    {
      "epoch": 2.350430550355672,
      "grad_norm": 0.20184745572890467,
      "learning_rate": 1.3650693513009383e-05,
      "loss": 0.0455,
      "step": 3140
    },
    {
      "epoch": 2.3579183826282293,
      "grad_norm": 0.169596188773399,
      "learning_rate": 1.3353048920278716e-05,
      "loss": 0.0479,
      "step": 3150
    },
    {
      "epoch": 2.365406214900786,
      "grad_norm": 0.14917837366418635,
      "learning_rate": 1.3058184313259609e-05,
      "loss": 0.0429,
      "step": 3160
    },
    {
      "epoch": 2.372894047173343,
      "grad_norm": 0.1733285926302345,
      "learning_rate": 1.2766122059962743e-05,
      "loss": 0.0481,
      "step": 3170
    },
    {
      "epoch": 2.3803818794459004,
      "grad_norm": 0.2093965501146865,
      "learning_rate": 1.2476884315816274e-05,
      "loss": 0.0448,
      "step": 3180
    },
    {
      "epoch": 2.3878697117184577,
      "grad_norm": 0.18594248248713646,
      "learning_rate": 1.2190493021985073e-05,
      "loss": 0.0467,
      "step": 3190
    },
    {
      "epoch": 2.3953575439910146,
      "grad_norm": 0.16942984740209885,
      "learning_rate": 1.190696990370634e-05,
      "loss": 0.044,
      "step": 3200
    },
    {
      "epoch": 2.4028453762635715,
      "grad_norm": 0.20780795898884566,
      "learning_rate": 1.1626336468641547e-05,
      "loss": 0.0444,
      "step": 3210
    },
    {
      "epoch": 2.410333208536129,
      "grad_norm": 0.1877611532249305,
      "learning_rate": 1.1348614005244896e-05,
      "loss": 0.0462,
      "step": 3220
    },
    {
      "epoch": 2.4178210408086858,
      "grad_norm": 0.18781521887297606,
      "learning_rate": 1.1073823581148396e-05,
      "loss": 0.0442,
      "step": 3230
    },
    {
      "epoch": 2.425308873081243,
      "grad_norm": 0.21254876145272328,
      "learning_rate": 1.0801986041563755e-05,
      "loss": 0.046,
      "step": 3240
    },
    {
      "epoch": 2.4327967053538,
      "grad_norm": 0.19264428196627223,
      "learning_rate": 1.053312200770099e-05,
      "loss": 0.0453,
      "step": 3250
    },
    {
      "epoch": 2.4402845376263573,
      "grad_norm": 0.19486648965999445,
      "learning_rate": 1.0267251875204237e-05,
      "loss": 0.0486,
      "step": 3260
    },
    {
      "epoch": 2.4477723698989142,
      "grad_norm": 0.1794513520891681,
      "learning_rate": 1.0004395812604517e-05,
      "loss": 0.0486,
      "step": 3270
    },
    {
      "epoch": 2.4552602021714716,
      "grad_norm": 0.21206051521451047,
      "learning_rate": 9.744573759789771e-06,
      "loss": 0.0438,
      "step": 3280
    },
    {
      "epoch": 2.4627480344440285,
      "grad_norm": 0.19700996952124708,
      "learning_rate": 9.487805426492274e-06,
      "loss": 0.0482,
      "step": 3290
    },
    {
      "epoch": 2.4702358667165853,
      "grad_norm": 0.21228953414506252,
      "learning_rate": 9.234110290793474e-06,
      "loss": 0.0436,
      "step": 3300
    },
    {
      "epoch": 2.4777236989891427,
      "grad_norm": 0.19212968566955094,
      "learning_rate": 8.9835075976464e-06,
      "loss": 0.0465,
      "step": 3310
    },
    {
      "epoch": 2.4852115312616996,
      "grad_norm": 0.19768485433302077,
      "learning_rate": 8.736016357415794e-06,
      "loss": 0.044,
      "step": 3320
    },
    {
      "epoch": 2.492699363534257,
      "grad_norm": 0.1555648274021362,
      "learning_rate": 8.491655344435955e-06,
      "loss": 0.0428,
      "step": 3330
    },
    {
      "epoch": 2.500187195806814,
      "grad_norm": 0.373596998380653,
      "learning_rate": 8.250443095586624e-06,
      "loss": 0.0438,
      "step": 3340
    },
    {
      "epoch": 2.507675028079371,
      "grad_norm": 0.16501799807209347,
      "learning_rate": 8.012397908886744e-06,
      "loss": 0.0389,
      "step": 3350
    },
    {
      "epoch": 2.515162860351928,
      "grad_norm": 0.21489132782538656,
      "learning_rate": 7.777537842106442e-06,
      "loss": 0.0454,
      "step": 3360
    },
    {
      "epoch": 2.5226506926244854,
      "grad_norm": 0.15763088048322882,
      "learning_rate": 7.545880711397124e-06,
      "loss": 0.0431,
      "step": 3370
    },
    {
      "epoch": 2.5301385248970423,
      "grad_norm": 0.17922300822241866,
      "learning_rate": 7.317444089940034e-06,
      "loss": 0.0436,
      "step": 3380
    },
    {
      "epoch": 2.537626357169599,
      "grad_norm": 0.16424108351844988,
      "learning_rate": 7.092245306613166e-06,
      "loss": 0.0456,
      "step": 3390
    },
    {
      "epoch": 2.5451141894421565,
      "grad_norm": 0.18010334729444985,
      "learning_rate": 6.870301444676691e-06,
      "loss": 0.0421,
      "step": 3400
    },
    {
      "epoch": 2.552602021714714,
      "grad_norm": 0.1723028445973375,
      "learning_rate": 6.651629340477061e-06,
      "loss": 0.0452,
      "step": 3410
    },
    {
      "epoch": 2.5600898539872707,
      "grad_norm": 0.20901834745316122,
      "learning_rate": 6.436245582169842e-06,
      "loss": 0.0459,
      "step": 3420
    },
    {
      "epoch": 2.5675776862598276,
      "grad_norm": 0.17199478159448103,
      "learning_rate": 6.224166508461338e-06,
      "loss": 0.0404,
      "step": 3430
    },
    {
      "epoch": 2.575065518532385,
      "grad_norm": 0.19158627840377215,
      "learning_rate": 6.0154082073691444e-06,
      "loss": 0.0456,
      "step": 3440
    },
    {
      "epoch": 2.582553350804942,
      "grad_norm": 0.1558898904506404,
      "learning_rate": 5.809986515001803e-06,
      "loss": 0.0414,
      "step": 3450
    },
    {
      "epoch": 2.590041183077499,
      "grad_norm": 0.15886872467705138,
      "learning_rate": 5.607917014357422e-06,
      "loss": 0.0443,
      "step": 3460
    },
    {
      "epoch": 2.597529015350056,
      "grad_norm": 0.15280680459738233,
      "learning_rate": 5.409215034141607e-06,
      "loss": 0.0437,
      "step": 3470
    },
    {
      "epoch": 2.605016847622613,
      "grad_norm": 0.17913868846561562,
      "learning_rate": 5.2138956476046495e-06,
      "loss": 0.0422,
      "step": 3480
    },
    {
      "epoch": 2.6125046798951703,
      "grad_norm": 0.17844436204951372,
      "learning_rate": 5.021973671398078e-06,
      "loss": 0.0449,
      "step": 3490
    },
    {
      "epoch": 2.6199925121677277,
      "grad_norm": 0.18856849829723674,
      "learning_rate": 4.833463664450688e-06,
      "loss": 0.0487,
      "step": 3500
    },
    {
      "epoch": 2.6274803444402846,
      "grad_norm": 0.20528343799966373,
      "learning_rate": 4.6483799268641545e-06,
      "loss": 0.0467,
      "step": 3510
    },
    {
      "epoch": 2.6349681767128414,
      "grad_norm": 0.14979090385501734,
      "learning_rate": 4.466736498828178e-06,
      "loss": 0.0429,
      "step": 3520
    },
    {
      "epoch": 2.642456008985399,
      "grad_norm": 0.2239161517666097,
      "learning_rate": 4.2885471595554895e-06,
      "loss": 0.0481,
      "step": 3530
    },
    {
      "epoch": 2.6499438412579557,
      "grad_norm": 0.19830391740131903,
      "learning_rate": 4.113825426236534e-06,
      "loss": 0.0438,
      "step": 3540
    },
    {
      "epoch": 2.657431673530513,
      "grad_norm": 0.1795288885555551,
      "learning_rate": 3.942584553014106e-06,
      "loss": 0.0457,
      "step": 3550
    },
    {
      "epoch": 2.66491950580307,
      "grad_norm": 0.16107000009695996,
      "learning_rate": 3.7748375299778592e-06,
      "loss": 0.0464,
      "step": 3560
    },
    {
      "epoch": 2.6724073380756272,
      "grad_norm": 0.20765240107374536,
      "learning_rate": 3.610597082178957e-06,
      "loss": 0.0434,
      "step": 3570
    },
    {
      "epoch": 2.679895170348184,
      "grad_norm": 0.19111151546280902,
      "learning_rate": 3.4498756686647426e-06,
      "loss": 0.042,
      "step": 3580
    },
    {
      "epoch": 2.6873830026207415,
      "grad_norm": 0.16827189551035052,
      "learning_rate": 3.292685481533603e-06,
      "loss": 0.0451,
      "step": 3590
    },
    {
      "epoch": 2.6948708348932984,
      "grad_norm": 0.18861466655076914,
      "learning_rate": 3.139038445010084e-06,
      "loss": 0.045,
      "step": 3600
    },
    {
      "epoch": 2.7023586671658553,
      "grad_norm": 0.19584563338054445,
      "learning_rate": 2.988946214540378e-06,
      "loss": 0.0459,
      "step": 3610
    },
    {
      "epoch": 2.7098464994384126,
      "grad_norm": 0.15954686645002236,
      "learning_rate": 2.8424201759081338e-06,
      "loss": 0.0439,
      "step": 3620
    },
    {
      "epoch": 2.71733433171097,
      "grad_norm": 0.1941717327073151,
      "learning_rate": 2.699471444370738e-06,
      "loss": 0.0445,
      "step": 3630
    },
    {
      "epoch": 2.724822163983527,
      "grad_norm": 0.1773335286678665,
      "learning_rate": 2.560110863816134e-06,
      "loss": 0.0453,
      "step": 3640
    },
    {
      "epoch": 2.7323099962560837,
      "grad_norm": 0.17325277085742166,
      "learning_rate": 2.424349005940224e-06,
      "loss": 0.044,
      "step": 3650
    },
    {
      "epoch": 2.739797828528641,
      "grad_norm": 0.1754045373681586,
      "learning_rate": 2.2921961694449267e-06,
      "loss": 0.0417,
      "step": 3660
    },
    {
      "epoch": 2.747285660801198,
      "grad_norm": 0.17073959998576332,
      "learning_rate": 2.163662379256909e-06,
      "loss": 0.0439,
      "step": 3670
    },
    {
      "epoch": 2.7547734930737553,
      "grad_norm": 0.2046296987463276,
      "learning_rate": 2.038757385767115e-06,
      "loss": 0.0419,
      "step": 3680
    },
    {
      "epoch": 2.762261325346312,
      "grad_norm": 0.19508584792058897,
      "learning_rate": 1.9174906640911372e-06,
      "loss": 0.0424,
      "step": 3690
    },
    {
      "epoch": 2.769749157618869,
      "grad_norm": 0.18859660851636165,
      "learning_rate": 1.799871413350418e-06,
      "loss": 0.044,
      "step": 3700
    },
    {
      "epoch": 2.7772369898914264,
      "grad_norm": 0.14524758983079547,
      "learning_rate": 1.6859085559744191e-06,
      "loss": 0.0442,
      "step": 3710
    },
    {
      "epoch": 2.7847248221639838,
      "grad_norm": 0.16780531858359773,
      "learning_rate": 1.5756107370238138e-06,
      "loss": 0.0415,
      "step": 3720
    },
    {
      "epoch": 2.7922126544365407,
      "grad_norm": 0.21276960304868772,
      "learning_rate": 1.468986323534649e-06,
      "loss": 0.0466,
      "step": 3730
    },
    {
      "epoch": 2.7997004867090975,
      "grad_norm": 0.17198749776786115,
      "learning_rate": 1.3660434038836433e-06,
      "loss": 0.0439,
      "step": 3740
    },
    {
      "epoch": 2.807188318981655,
      "grad_norm": 0.17547167442782416,
      "learning_rate": 1.2667897871746103e-06,
      "loss": 0.0458,
      "step": 3750
    },
    {
      "epoch": 2.8146761512542118,
      "grad_norm": 0.18917892641968811,
      "learning_rate": 1.1712330026460938e-06,
      "loss": 0.0438,
      "step": 3760
    },
    {
      "epoch": 2.822163983526769,
      "grad_norm": 0.19088212934056334,
      "learning_rate": 1.079380299100191e-06,
      "loss": 0.0426,
      "step": 3770
    },
    {
      "epoch": 2.829651815799326,
      "grad_norm": 0.17853452499383884,
      "learning_rate": 9.9123864435266e-07,
      "loss": 0.0436,
      "step": 3780
    },
    {
      "epoch": 2.8371396480718833,
      "grad_norm": 0.1857124444842489,
      "learning_rate": 9.068147247043635e-07,
      "loss": 0.0438,
      "step": 3790
    },
    {
      "epoch": 2.8446274803444402,
      "grad_norm": 0.18353300500377318,
      "learning_rate": 8.261149444340588e-07,
      "loss": 0.0453,
      "step": 3800
    },
    {
      "epoch": 2.8521153126169976,
      "grad_norm": 0.2634178540001802,
      "learning_rate": 7.491454253125863e-07,
      "loss": 0.0435,
      "step": 3810
    },
    {
      "epoch": 2.8596031448895545,
      "grad_norm": 0.24202908055509845,
      "learning_rate": 6.75912006138446e-07,
      "loss": 0.0408,
      "step": 3820
    },
    {
      "epoch": 2.8670909771621114,
      "grad_norm": 0.20179247793116087,
      "learning_rate": 6.064202422949084e-07,
      "loss": 0.0474,
      "step": 3830
    },
    {
      "epoch": 2.8745788094346687,
      "grad_norm": 0.17023941895004935,
      "learning_rate": 5.406754053285835e-07,
      "loss": 0.0448,
      "step": 3840
    },
    {
      "epoch": 2.8820666417072256,
      "grad_norm": 0.1648386024495984,
      "learning_rate": 4.78682482549514e-07,
      "loss": 0.0457,
      "step": 3850
    },
    {
      "epoch": 2.889554473979783,
      "grad_norm": 0.1789630292426452,
      "learning_rate": 4.2044617665286667e-07,
      "loss": 0.0429,
      "step": 3860
    },
    {
      "epoch": 2.89704230625234,
      "grad_norm": 0.22809427225053772,
      "learning_rate": 3.6597090536217296e-07,
      "loss": 0.0412,
      "step": 3870
    },
    {
      "epoch": 2.904530138524897,
      "grad_norm": 0.201545090570259,
      "learning_rate": 3.1526080109422487e-07,
      "loss": 0.0506,
      "step": 3880
    },
    {
      "epoch": 2.912017970797454,
      "grad_norm": 0.18282712222089825,
      "learning_rate": 2.683197106455759e-07,
      "loss": 0.0458,
      "step": 3890
    },
    {
      "epoch": 2.9195058030700114,
      "grad_norm": 0.189491723636163,
      "learning_rate": 2.2515119490074677e-07,
      "loss": 0.0458,
      "step": 3900
    },
    {
      "epoch": 2.9269936353425683,
      "grad_norm": 0.17451128498079857,
      "learning_rate": 1.857585285620911e-07,
      "loss": 0.0454,
      "step": 3910
    },
    {
      "epoch": 2.934481467615125,
      "grad_norm": 0.23953124798028994,
      "learning_rate": 1.5014469990138336e-07,
      "loss": 0.0444,
      "step": 3920
    },
    {
      "epoch": 2.9419692998876825,
      "grad_norm": 0.17609772433251797,
      "learning_rate": 1.1831241053313901e-07,
      "loss": 0.0432,
      "step": 3930
    },
    {
      "epoch": 2.94945713216024,
      "grad_norm": 0.1847700092006499,
      "learning_rate": 9.026407520965063e-08,
      "loss": 0.0418,
      "step": 3940
    },
    {
      "epoch": 2.9569449644327968,
      "grad_norm": 0.17454136579482168,
      "learning_rate": 6.600182163785106e-08,
      "loss": 0.0444,
      "step": 3950
    },
    {
      "epoch": 2.9644327967053536,
      "grad_norm": 0.19719344242961,
      "learning_rate": 4.55274903178704e-08,
      "loss": 0.0449,
      "step": 3960
    },
    {
      "epoch": 2.971920628977911,
      "grad_norm": 0.16293203234607423,
      "learning_rate": 2.8842634403425383e-08,
      "loss": 0.0461,
      "step": 3970
    },
    {
      "epoch": 2.979408461250468,
      "grad_norm": 0.19035478818130597,
      "learning_rate": 1.5948519584013664e-08,
      "loss": 0.0471,
      "step": 3980
    },
    {
      "epoch": 2.986896293523025,
      "grad_norm": 0.1824950201154006,
      "learning_rate": 6.846123988896169e-09,
      "loss": 0.0431,
      "step": 3990
    },
    {
      "epoch": 2.994384125795582,
      "grad_norm": 0.20635216539830142,
      "learning_rate": 1.5361381128842223e-09,
      "loss": 0.0436,
      "step": 4000
    },
    {
      "epoch": 3.0,
      "step": 4008,
      "total_flos": 2013258183606272.0,
      "train_loss": 0.06899598889989768,
      "train_runtime": 44326.4614,
      "train_samples_per_second": 2.169,
      "train_steps_per_second": 0.09
    }
  ],
  "logging_steps": 10,
  "max_steps": 4008,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2013258183606272.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
